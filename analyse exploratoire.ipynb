{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advised-aggregate",
   "metadata": {},
   "source": [
    "# Pr√©sentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-kitty",
   "metadata": {},
   "source": [
    "Blabla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-coalition",
   "metadata": {},
   "source": [
    "# Sommaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-mistake",
   "metadata": {},
   "source": [
    "### [Biblioth√®ques](#1_bibli)\n",
    "### [Fonctions](#1_funcs)\n",
    "### [Donn√©es](#1_donnees)\n",
    "### [Profiling](#1_profiling)\n",
    "### [Rangement des colonnes](#1_rangement)\n",
    "<!-- ### [Id√©e](#1_idee)\n",
    "### [Nettoyage](#1_nettoyage)\n",
    "- [Labels](#nett_1)\n",
    "- [Categories - Compl√©tion de donn√©es par ML](#nett_2)\n",
    "- [Packaging](#nett_3)\n",
    "\n",
    "### [Analyses Univari√©es](#1_univ)\n",
    "- [Labels](#univ_1)\n",
    "- [Categories](#univ_2)\n",
    "- [Packaging](#univ_3)\n",
    "- [Additifs](#univ_4)\n",
    "- [Huile de palme](#univ_5)\n",
    "- [Graisse satur√©e](#univ_6)\n",
    "- [Nutriscore num√©rique](#univ_7)\n",
    "- [Nutriscore cat√©gorique](#univ_8)\n",
    "\n",
    "### [Analyses Bivari√©es](#1_biv)\n",
    "- [Entre l'emballage et le Nutriscore (Score)](#biv_emb_nutr_score)\n",
    "- [Entre l'emballage et le Nutriscore (Grade)](#biv_emb_nutr_grade)\n",
    "- [Entre l'emballage et le nombre d'additifs](#biv_emb_add)\n",
    "- [Entre l'emballage et les labels](#biv_emb_label)\n",
    "\n",
    "### [Analyse Statistique](#1_anal_stat)\n",
    "### [Tests Statistique](#1_tests_stat)\n",
    "### [Conclusion](#1_conclusion) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-measure",
   "metadata": {},
   "source": [
    "<a id='1_bibli'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-details",
   "metadata": {},
   "source": [
    "# Import de biblioth√®ques üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eight-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-hawaii",
   "metadata": {},
   "source": [
    "<a id='1_funcs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-faith",
   "metadata": {},
   "source": [
    "# Fonctions ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "small-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_histo(data, title=None, xlabel=None, drop_outliers=False, bins='sturges', plot_density=True):\n",
    "#     \"\"\"Plots an histogram from an array of numbers. Bins can be set or automatically calculated by sturges method\n",
    "#     It's also possible to plot the density curve an drop outliers\"\"\"\n",
    "#     if drop_outliers:\n",
    "#         data = data[data.between(data.quantile(drop_outliers), data.quantile(1 - drop_outliers))]\n",
    "#     if bins == 'sturges':\n",
    "#         bins = int(1+log2(len(data)))\n",
    "#     plt.style.use(\"seaborn\")\n",
    "#     if plot_density:\n",
    "#         density = gaussian_kde(data)\n",
    "#         xs = np.linspace(data.min(),data.max(),200)\n",
    "#         density.covariance_factor = lambda : .25\n",
    "#         density._compute_covariance()\n",
    "#         plt.plot(xs,density(xs), label=\"Courbe de densit√©\")\n",
    "#         plt.legend()\n",
    "#     plt.ylabel(\"frequency\")\n",
    "#     plt.xlabel(xlabel)\n",
    "#     plt.title(title)\n",
    "#     plt.hist(data, bins=bins, density=True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "mighty-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_custom(label_string, delimiter=','):\n",
    "#     \"\"\"splits a string into a list\"\"\"\n",
    "#     return label_string.split(delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "loved-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_unique_elements(panda_serie):\n",
    "#     \"\"\"This functions returns the list of unique elements \n",
    "#     out of a panda serie of strings with comma separated elements\"\"\"\n",
    "#     all_labels = set()\n",
    "#     for labels in panda_serie.map(split_custom):\n",
    "#         for label in labels:\n",
    "#             all_labels.add(label)\n",
    "#     return list(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-hungarian",
   "metadata": {},
   "source": [
    "<a id='fonctionbio'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "surprising-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_bio(labels):\n",
    "#     \"\"\"From a list of labels this function returns a booleean if 'organic' or 'bio' is in one of the labels\"\"\"\n",
    "#     bool_test = False\n",
    "#     for label in labels:\n",
    "#         label = label.lower()\n",
    "#         if 'organic' in label or 'bio' in label:\n",
    "#             bool_test = True\n",
    "#             break\n",
    "#     return bool_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-slovakia",
   "metadata": {},
   "source": [
    "Retour au [script](#backbio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-surgeon",
   "metadata": {},
   "source": [
    "<a id='fonctionvege'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "indirect-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_vege(labels):\n",
    "#     \"\"\"From a list of labels this function returns a booleean if 'vegeterian' or 'vegan' is in one of the labels\"\"\"\n",
    "#     bool_test = False\n",
    "#     for label in labels:\n",
    "#         label = label.lower()\n",
    "#         if 'vegetarian' in label or 'vegan' in label:\n",
    "#             bool_test = True\n",
    "#             break\n",
    "#     return bool_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-cisco",
   "metadata": {},
   "source": [
    "Retour au [script](#backvege)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-headset",
   "metadata": {},
   "source": [
    "<a id='fonctionnegation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "massive-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # This function works but would be more efficient if it would detect the language. We'll save that for later\n",
    "# def test_no_something(labels, dict_something):\n",
    "#     \"\"\"From a list of labels this function returns a booleean if 'preserative' and a negation is in one of the labels\"\"\"\n",
    "#     for word, negations in dict_something.items():\n",
    "#         for label in labels:\n",
    "#             label = label.lower()\n",
    "#             label = label.replace('-', ' ')\n",
    "#             bool_list = []\n",
    "#             #looking for word preservative\n",
    "#             preservative_in_label = bool(re.match(r'.*\\b{}.*\\b'.format(word), label))\n",
    "#             if preservative_in_label:\n",
    "#                 #looking for negation\n",
    "#                 for negation in negations:\n",
    "#                     if bool(re.match(r'.*\\b{}\\b'.format(negation), label)):\n",
    "#                         return True\n",
    "\n",
    "#     return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-milton",
   "metadata": {},
   "source": [
    "- Retour au [script](#backconserv) Conservateurs\n",
    "- Retour au [script](#backcolor) Colorants\n",
    "- Retour au [script](#backGMO) OGMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-andrews",
   "metadata": {},
   "source": [
    "<a id='plot_bar'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "applicable-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(data, labels, color='purple', label=None, rotation=False, ylabel='Proportion par rapport au nombre de poduits du dataset (%)'):\n",
    "    \"\"\"Custom function to plot a bars\"\"\"\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.style.use('seaborn')\n",
    "    plt.bar(list(range(1, len(data)+1)), data, color=color, label=label)\n",
    "    if rotation:\n",
    "        angle=90\n",
    "    else:\n",
    "        angle=0\n",
    "    plt.xticks(list(range(1, len(data)+1)), labels, rotation=angle, fontsize=12)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-difference",
   "metadata": {},
   "source": [
    "- Retour au [script](#univ_1_plot_1) Labels\n",
    "- Retour au [script](#univ_1_plot_2) Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-calibration",
   "metadata": {},
   "source": [
    "<a id='launch_kmeans_mlflow'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "isolated-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def launch_kmeans_mlflow(data_kmeans, n_clusters, comment, col_target, max_iter=300, n_init=10, init='k-means++', random_state=41):\n",
    "#     \"\"\"Trains a KMeans model and saves the results into MLFLOW\"\"\"\n",
    "#     with mlflow.start_run(run_name=comment):\n",
    "        \n",
    "#         #Train\n",
    "#         start = time.time()\n",
    "#         kmeans = KMeans(n_clusters=n_clusters, max_iter=max_iter, n_init=n_init, init=init, random_state=random_state).fit(data_kmeans.drop(columns=[col_target]))\n",
    "#         elapsed = time.time() - start\n",
    "        \n",
    "#         #Predict\n",
    "#         data_kmeans['predicted_group'] = kmeans.predict(data_kmeans.drop(columns=[col_target]))\n",
    "        \n",
    "#         #Undestang predictions\n",
    "#         categs_group_number = {}\n",
    "#         for i in range(n_clusters):\n",
    "#             categs_group_number[i] = data_kmeans[data_kmeans['predicted_group'] == i][col_target].value_counts().index[0]\n",
    "        \n",
    "#         data_kmeans = data_kmeans.merge(pd.Series(categs_group_number, name='predicted_group_label'), left_on='predicted_group', right_index=True)\n",
    "        \n",
    "#         #Test\n",
    "#         data_kmeans['model_is_right'] = data_kmeans[col_target] == data_kmeans['predicted_group_label']\n",
    "        \n",
    "#         perf = data_kmeans.model_is_right.value_counts(normalize=True).loc[True]\n",
    "        \n",
    "#         mlflow.log_param(\"n_clusters\", n_clusters)\n",
    "#         mlflow.log_param(\"max_iter\", max_iter)\n",
    "#         mlflow.log_param(\"n_init\", n_init)\n",
    "#         mlflow.log_param(\"init\", init)\n",
    "#         mlflow.log_param(\"random_state\", random_state)\n",
    "        \n",
    "#         mlflow.log_metric(\"accuracy\", perf)\n",
    "#         mlflow.log_metric(\"distinct_categs_predicted\", len(data_kmeans.predicted_group_label.unique()))\n",
    "#         mlflow.log_metric(\"trainig_time\", elapsed)\n",
    "#         mlflow.log_metric(\"inertie\", kmeans.inertia_)\n",
    "#         mlflow.log_metric(\"nb_iter\", kmeans.n_iter_)\n",
    "\n",
    "        \n",
    "#         mlflow.set_tag(\"columns_passed\", str(data_kmeans.drop(columns=[col_target, 'predicted_group', \n",
    "#                                                                       'predicted_group_label']).columns.values))\n",
    "#         mlflow.end_run()\n",
    "#     return data_kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-reset",
   "metadata": {},
   "source": [
    "- Retour au [script](#categ_kmeans) K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-standing",
   "metadata": {},
   "source": [
    "<a id='launch_gb_mlflow'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "structural-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def launch_gb_mlflow(data, comment, col_target, n_estimators=50, learning_rate=0.2,  max_depth=5, random_state=41):\n",
    "#     \"\"\"Trains a GBoost model and saves the results into MLFLOW\"\"\"\n",
    "#     data_train, data_test = train_test_split(data, train_size=0.7, random_state=random_state)\n",
    "#     with mlflow.start_run(run_name=comment):\n",
    "#         start_time = time.time()\n",
    "#         gb_cl = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate,  max_depth=max_depth, random_state=random_state).fit(data_train.drop(columns=[col_target]), data_train[col_target])\n",
    "#         elapsed = time.time() - start_time\n",
    "        \n",
    "#         mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "#         mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "#         mlflow.log_param(\"max_depth\", max_depth)\n",
    "#         mlflow.log_param(\"random_state\", random_state)\n",
    "        \n",
    "#         mlflow.log_metric(\"score sur train\", gb_cl.score(data_train.drop(columns=[col_target]), data_train[col_target]))\n",
    "#         mlflow.log_metric(\"score sur test\", gb_cl.score(data_test.drop(columns=[col_target]), data_test[col_target]))\n",
    "#         mlflow.log_metric(\"time_train\", elapsed)\n",
    "        \n",
    "#         mlflow.end_run()\n",
    "    \n",
    "#     data_result = pd.DataFrame({\"actual\": data_test[col_target], \"predicted\" : gb_cl.predict(data_test.drop(columns=[col_target]))})\n",
    "    \n",
    "#     return (data_result, gb_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-payroll",
   "metadata": {},
   "source": [
    "- Retour au [script](#categ_gb) Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-peripheral",
   "metadata": {},
   "source": [
    "<a id='parser_prediction'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "maritime-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parser_prediction(row, data_unknown, col_modeled, col_predicted):\n",
    "#     \"\"\"Completes unknown values in a column from data in another dataset\"\"\"\n",
    "#     if row[col_modeled] == 'unknown':\n",
    "#         return data_unknown.loc[row.name][col_predicted]\n",
    "#     else:\n",
    "#         return row[col_modeled]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-pleasure",
   "metadata": {},
   "source": [
    "- Retour au [script](#back_parse_gb_results) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-sweden",
   "metadata": {},
   "source": [
    "<a id='1_donnees'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-creator",
   "metadata": {},
   "source": [
    "# Donn√©es üéÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "functioning-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2016 = pd.read_csv('data/2016-building-energy-benchmarking.csv', sep=',')\n",
    "data_2015 = pd.read_csv('data/2015-building-energy-benchmarking.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "necessary-nursing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3376, 46)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2016.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "nominated-airport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3340, 47)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2015.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "mighty-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_2015, data_2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "measured-trailer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6716, 56)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-feedback",
   "metadata": {},
   "source": [
    "On remarque ici un probl√®me de format des colonnes entre les donn√©es 2015 et 2016. Il faut retrouver les correspondances entre les colonnes pour obtenir un dataset robuste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-dairy",
   "metadata": {},
   "source": [
    "<a id='1_profiling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-baghdad",
   "metadata": {},
   "source": [
    "# Profiling üîç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-burns",
   "metadata": {},
   "source": [
    "Etant donn√©es les dimensions de ce dataset, je vais r√©aliser l'analyse pr√©liminaire avec Pandas Profiling. L'analyse est export√©e en HTML pour une meilleure lisibilit√© du NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "musical-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(data, title=\"Report on Seattle Building Benchmarking\", minimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "subsequent-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f0de22471b460a9fed9c84fdb3d3f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c51ded3bd94b6c95e11acac84ff411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9a50cfce5447848063cc06a714254f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa0355cf1f848ef9f0ee9d1a9583407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile.to_file('profile_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-sleep",
   "metadata": {},
   "source": [
    "Voir le report : [cliquer ici](profile_report.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-barrel",
   "metadata": {},
   "source": [
    "<a id='1_rangement'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-defeat",
   "metadata": {},
   "source": [
    "# Rangement des colonnes üóÇÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-stephen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_OC_P04",
   "language": "python",
   "name": "env_oc_p04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
